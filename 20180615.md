#### 1. [【领域报告】行人再识别年度进展 |VALSE2018之十][Title-0615-01] +  深度学习大讲堂 + 李玺  

作者介绍：浙江大学教授   
Person ReID(Person Re-identification)是在多个摄像头下快速识别一个人ID的问题，具有一定挑战性。  
普遍做法主要是： 特征提取 + 特征匹配  
![img][img-0615-01-01]   
* 特征提取
	* 主流是CNN
* 特征匹配方法
	* 基于预先定义的位置(global,local stripes,grid pathes)
	* 基于semantic regions，借助语义(Person parts, salient regions和attention regions)   

从strips、grids、attention以及pose，目前的一些算法可以分类：  
![img][img-0615-01-02]  

* Strips
	* `DeepMetric(2014)`：把一幅图片强行分成三大块，每一大块做一个SCNN，再将各个部分整合。想法非常简单，实际应用过程中相对有效。
	* `DeepReID(2014)`：把一个人的结构分成很多小块，每一个小块进行操作。这个方法比较直接，更加细致。缺陷是在识别较为复杂的情况时，或者任何人之间特征区分较差时会受到噪音干扰。
	* `AlignedReID(2017)`：通过动态规划计算距离，需要动态匹配的过程，比较复杂，但效果不错。过程分为两个部分，一个是水平的pooling，一个是global pooling，再将两部分融合，得到local distance和global distance，再加入hard sample mining。
* Grids
	* `IDLA(2015)`:它将两个图片转化匹配，认为在另一个图像的邻域网格总能找到匹配。在难以匹配的情况下，可以到邻域寻找匹配，所以性能提高很多。
	* DCSL(2016):将网络结构转化成一个空间金字塔，在一层匹配不了的情况下，到上一层匹配。
* Attention
	* `Part-Aligned(2017)`:将一个人进行匹配时不是所有区域都参与到匹配中，我们希望加入attention map，来自动发现适合做re-identify的pattern，再做triplet loss，能够在性能上提高7到8个点。
	* `HydraPlus-Net(2017)`:多层attention，attention map有多个layer，还有遗忘skip的功能，需要把很多过程整合起来得到一个结果。(泛化能力不好)
	* `HA-CNN(2018)`:定义了两种attention，一种是hard attention，有主干道，一种是soft attention，加入一些分支，然后把soft和hard枝干融合。最后只放出market数据集的结果，相比HA-CNN提高很多，但没有放出CHUK03的结果，无法重复实验。
* Pose
	* `PDC(2017)`:将Pose信息嵌入到结构网络中，生成一个modified结构图像，然后对这个结构图像进行识别，效果会有极大提高。
	* `PSE(2018)`:引入视角关系，将多视角结构进行整合，最后得到的结果也还不错。   

Performances:  
![img][img-0615-01-03]   

参考文献链接：
https://pan.baidu.com/s/1csXOCetmUb-LDfAI6jssGw    密码: h8ft  

#### 2.[【领域报告】图像OCR年度进展|VALSE2018之十一][Title-0615-02] + 深度学习大讲堂 + 白翔   
作者介绍：华中科技大学教授     
* 文本检测  
* 文本识别  
* `端对端识别`:将检测和识别统一在一个网络框架下的思路。目前来说这种做法训练起来较为困难。它的主要思路是通过RPN产生一些proposal，然后在后面接上序列识别网络。为了使网络有效，往往需要对检测和识别模块分别进行预训练，预训练完后再把两个模块一起进行进一步训练。这种方法较为复杂。 
* 数据集   

参考文献链接：
https://pan.baidu.com/s/10LT47XsUpzBjHu8S9mcy7Q 密码: k2iv





[Title-0615-01]:https://mp.weixin.qq.com/s/leuILzYz40PqrwsCatYhPw
[Title-0615-02]:https://mp.weixin.qq.com/s/0ysaJGNslckesv21o752FA
[img-0615-01-01]:./img/20180615-01-01.jpg
[img-0615-01-02]:./img/20180615-01-02.jpg
[img-0615-01-03]:./img/20180615-01-03.jpg